{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Author:  Dharavath Ramdas\n",
        "github link: https://github.com/dharavathramdas101   \n",
        "linkedin: https://www.linkedin.com/in/dharavath-ramdas-a283aa213/"
      ],
      "metadata": {
        "id": "2ztR1oCg6KWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture"
      ],
      "metadata": {
        "id": "1RwFFd_xVTEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeNet-5\n",
        "it's a classification Architecture \n",
        "\n",
        "Lenet-5 is one of the earliest pre-trained models proposed by Yann LeCun and others in the year 1998, in the research paper Gradient-Based Learning Applied to Document Recognition. They used this architecture for recognizing the handwritten and machine-printed characters.\n",
        "\n",
        "The main reason behind the popularity of this model was its simple and straightforward architecture. It is a multi-layer convolution neural network for image classification.\n",
        "\n",
        "pincode --> pinecode recognization, character / number\n",
        "\n",
        "input size : 32*32"
      ],
      "metadata": {
        "id": "KvMkOK-bUomy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture of the Model\n",
        " Let’s understand the architecture of Lenet-5. The network has 5 layers with learnable parameters and hence named Lenet-5. It has three sets of convolution layers with a combination of average pooling. After the convolution and average pooling layers, we have two fully connected layers. At last, a Softmax classifier which classifies the images into respective class.\n",
        "\n",
        " The input to this model is a 32 X 32 grayscale image hence the number of channels is one.\n",
        "\n",
        "32 X 32 grayscale image\n",
        "\n",
        " \n",
        "\n",
        "We then apply the first convolution operation with the filter size 5X5 and we have 6 such filters. As a result, we get a feature map of size 28X28X6. Here the number of channels is equal to the number of filters applied.\n",
        "\n",
        "Lenet-5 - first convolution operation\n",
        "\n",
        "After the first pooling operation, we apply the average pooling and the size of the feature map is reduced by half. Note that, the number of channels is intact.\n",
        "\n",
        "first pooling operation\n",
        "\n",
        "Next, we have a convolution layer with sixteen filters of size 5X5. Again the feature map changed it is 10X10X16. The output size is calculated in a similar manner. After this, we again applied an average pooling or subsampling layer, which again reduce the size of the feature map by half i.e 5X5X16.\n",
        "\n",
        "Lenet-5 size 5X5\n",
        "\n",
        "Then we have a final convolution layer of size 5X5 with 120 filters. As shown in the above image. Leaving the feature map size 1X1X120. After which flatten result is 120 values.\n",
        "\n",
        "After these convolution layers, we have a fully connected layer with eighty-four neurons. At last, we have an output layer with ten neurons since the data have ten classes."
      ],
      "metadata": {
        "id": "L2N6QuPWVkuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r5lBvL6ZVkk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  \n",
        "from IPython.display import Image\n",
        "Image(url='https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-52-17.png', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "cellView": "form",
        "id": "1K56LqROWWUz",
        "outputId": "6e20fc82-0816-4f54-feff-422672efa10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-52-17.png\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Details\n",
        "Let’s understand the architecture in more detail.\n",
        "\n",
        "The first layer is the input layer with feature map size 32X32X1.\n",
        "\n",
        "Then we have the first convolution layer with 6 filters of size 5X5 and stride is 1. The activation function used at his layer is tanh. The output feature map is  28X28X6.\n",
        "\n",
        "Next, we have an average pooling layer with filter size 2X2 and stride 1. The resulting feature map is 14X14X6. Since the pooling layer doesn’t affect the number of channels.\n",
        "\n",
        "After this comes the second convolution layer with 16 filters of 5X5 and stride 1. Also, the activation function is tanh. Now the output size is 10X10X16.\n",
        "\n",
        "Again comes the other average pooling layer of 2X2 with stride 2. As a result, the size of the feature map reduced to 5X5X16.\n",
        "\n",
        "The final pooling layer has 120 filters of 5X5  with stride 1 and activation function tanh. Now the output size is 120.\n",
        "\n",
        "The next is a fully connected layer with 84 neurons that result in the output to 84 values and the activation function used here is again tanh.\n",
        "\n",
        "The last layer is the output layer with 10 neurons and  Softmax function. The Softmax gives the probability that a data point belongs to a particular class. The highest value is then predicted.\n",
        "\n",
        "This is the entire architecture of the Lenet-5 model. The number of trainable parameters of this architecture is around sixty thousand."
      ],
      "metadata": {
        "id": "Kv-QuAvJXIeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "Image(url='https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-56-51.png', width=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "cellView": "form",
        "id": "Sp6OyHYdUmuu",
        "outputId": "25e72bd9-fcf5-411d-abe5-5a545cef715f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-56-51.png\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ANvYl6iaKwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeNet - 5 Practical implementation"
      ],
      "metadata": {
        "id": "f08aWy_LaMh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MZGPvjgqRI7E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "from keras.models import Sequential\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load data"
      ],
      "metadata": {
        "id": "lnOU397C037W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRtJF58CStkQ",
        "outputId": "8248bc5a-778c-4778-c445-529282b80ff5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we dont have channel dimention so we have to add gray scale dimention 1 "
      ],
      "metadata": {
        "id": "DX82tgF407BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmxwzrNQS7ZG",
        "outputId": "c3b5a25b-ea19-4c19-f05b-cb51bed16595"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ZeXLxTStnc",
        "outputId": "2968566c-0c2d-4181-d0f1-d35812892035"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVspkF530tid",
        "outputId": "d00c9431-2d84-42d4-9c80-c971ac0d1ca9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGKwVDYJ1y63",
        "outputId": "737b578c-eaed-4247-b18e-35393c06c810"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding channel \n",
        "\n",
        "## architecture allways take 3 channel input but your 2 chanel only so we add another one\n"
      ],
      "metadata": {
        "id": "-j4Gss9A0xXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performing reshaping\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28,28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0],28,28, 1)"
      ],
      "metadata": {
        "id": "RzHTBAe-StrZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3kwumIvTNqa",
        "outputId": "715189b4-b8a1-40a9-b020-05330f7f99b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pixcel range in between 0 to 255"
      ],
      "metadata": {
        "id": "Aqsi3Mdd2Ga2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255 #min max 0-1\n",
        "     "
      ],
      "metadata": {
        "id": "UtSk3V7TSttp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## onehot encoding on labeled data  0 to 9\n",
        "## where 0 give staring 0 if 1 it gives second index inn"
      ],
      "metadata": {
        "id": "5HBK-8dN2f5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcQVLkTXTUbI",
        "outputId": "382585c6-22db-48d7-d19e-cf52fb1ebdfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot Encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "     "
      ],
      "metadata": {
        "id": "PAZsX-y9TUod"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tm3VMeaTrz4",
        "outputId": "2a4a86cd-b021-411d-80af-215e5f93461e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Architecture\n",
        "\n",
        "# your data dimention is only 28,28,1 "
      ],
      "metadata": {
        "id": "n7fGpRVuT2u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5,5), padding = 'valid', activation='tanh', input_shape = (28,28,1)))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(16, kernel_size = (5,5), padding = 'valid', activation='tanh'))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120, activation='tanh'))\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FujX39JEUIHz",
        "outputId": "556249f9-fc08-4127-b1e7-57f4d245cb99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 12, 12, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 4, 4, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = keras.metrics.categorical_crossentropy, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "     \n"
      ],
      "metadata": {
        "id": "TkIutZxVUIRO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs=10 , verbose= 1, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr5IqNXTUIZF",
        "outputId": "43774196-1b82-4b42-9709-8ebcfe2db969"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 26s 52ms/step - loss: 0.3617 - accuracy: 0.8961 - val_loss: 0.1574 - val_accuracy: 0.9538\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.1321 - accuracy: 0.9602 - val_loss: 0.0998 - val_accuracy: 0.9687\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0872 - accuracy: 0.9737 - val_loss: 0.0798 - val_accuracy: 0.9757\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.0649 - val_accuracy: 0.9786\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0580 - val_accuracy: 0.9807\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.0499 - val_accuracy: 0.9843\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.0451 - val_accuracy: 0.9841\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0503 - val_accuracy: 0.9841\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0475 - val_accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0509 - val_accuracy: 0.9841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f534db7ad30>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FnRcfJ0UZdd",
        "outputId": "5f4d535e-509e-4eeb-ca63-01fdb7f6444f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0509 - accuracy: 0.9841\n",
            "Test loss: 0.05088185891509056\n",
            "Test accuracy: 0.9840999841690063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuM6LsdXamQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}